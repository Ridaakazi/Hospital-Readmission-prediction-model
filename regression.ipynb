{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "df = pd.read_csv(\"HDHI Admission data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'EMPTY' strings with NaN\n",
    "df.replace('EMPTY', pd.NA, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing values\n",
    "numerical_cols = df.select_dtypes(include=['number']).columns\n",
    "df[numerical_cols] = df[numerical_cols].fillna(df[numerical_cols].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'D.O.A' to datetime\n",
    "df['D.O.A'] = pd.to_datetime(df['D.O.A'], errors='coerce')\n",
    "\n",
    "# Sort by 'MRD No.' and 'D.O.A' to ensure the latest entry is first\n",
    "df.sort_values(by=['MRD No.', 'D.O.A'], ascending=[True, False], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add 'Readmission Count' and 'Readmission' columns\n",
    "df['Readmission Count'] = df.groupby('MRD No.')['MRD No.'].transform('count')\n",
    "df['Readmission'] = df['Readmission Count'].apply(lambda x: 1 if x > 1 else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates keeping the oldest entry based on 'D.O.A'\n",
    "df_latest = df.drop_duplicates(subset=['MRD No.'], keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "to_drop = ['SNO', 'D.O.D', 'month year']\n",
    "df_latest.drop(columns=to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical variables\n",
    "label_encoders = {\n",
    "    'GENDER': LabelEncoder(),\n",
    "    'RURAL': LabelEncoder(),\n",
    "    'TYPE OF ADMISSION-EMERGENCY/OPD': LabelEncoder(),\n",
    "    'OUTCOME': LabelEncoder()\n",
    "}\n",
    "\n",
    "for col, le in label_encoders.items():\n",
    "    if col in df_latest.columns:\n",
    "        df_latest[col] = le.fit_transform(df_latest[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create input features and target\n",
    "input_df = df_latest.drop(columns=['OUTCOME', 'D.O.A', 'MRD No.', 'Readmission', 'Readmission Count'])\n",
    "target = df_latest['Readmission Count']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle any remaining NaN values\n",
    "input_df.fillna(0, inplace=True)\n",
    "\n",
    "new_input_df = input_df[['GENDER', 'TYPE OF ADMISSION-EMERGENCY/OPD', 'RURAL', 'PLATELETS', 'GLUCOSE', 'TLC', 'UREA', 'HB', 'AGE', 'CREATININE', 'DURATION OF STAY', 'EF', 'BNP', 'duration of intensive unit stay']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(new_input_df, target, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models and parameter grids for regression models\n",
    "regression_models_and_parameters = {\n",
    "    \"Decision Tree Regressor\": (Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('regressor', DecisionTreeRegressor())\n",
    "    ]), {\n",
    "        'regressor__max_depth': [None, 10, 20, 30],\n",
    "        'regressor__min_samples_split': [2, 5, 10]\n",
    "    }),\n",
    "\n",
    "    \"Random Forest Regressor\": (Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('regressor', RandomForestRegressor())\n",
    "    ]), {\n",
    "        'regressor__n_estimators': [50, 100, 200],\n",
    "        'regressor__max_depth': [None, 10, 20],\n",
    "        'regressor__min_samples_split': [2, 5, 10]\n",
    "    }),\n",
    "    \n",
    "    \"KNN Regressor\": (Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('regressor', KNeighborsRegressor())\n",
    "    ]), {\n",
    "        'regressor__n_neighbors': [3, 5, 7],\n",
    "        'regressor__weights': ['uniform', 'distance']\n",
    "    }),\n",
    "\n",
    "    \"Linear Regression\": (Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('regressor', LinearRegression())\n",
    "    ]), {})\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "\n",
      "Decision Tree Regressor Best Model Parameters: {'regressor__max_depth': 10, 'regressor__min_samples_split': 10}\n",
      "Decision Tree Regressor Best Model R2 Score: -0.127607590608535\n",
      "Decision Tree Regressor Predictions vs Actual:\n",
      "       Predicted  Actual\n",
      "12118   1.283713       1\n",
      "12618   1.348348       2\n",
      "2997    1.193114       1\n",
      "11637   1.250000       1\n",
      "10367   1.000000       1\n",
      "...          ...     ...\n",
      "4969    1.154506       1\n",
      "15453   1.212644       1\n",
      "1653    1.406250       1\n",
      "5219    1.193114       1\n",
      "14817   1.193182       2\n",
      "\n",
      "[2449 rows x 2 columns]\n",
      "\n",
      "Decision Tree Regressor Model Mean Squared Error:\n",
      "0.7047625230346098\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "\n",
      "Random Forest Regressor Best Model Parameters: {'regressor__max_depth': 10, 'regressor__min_samples_split': 10, 'regressor__n_estimators': 200}\n",
      "Random Forest Regressor Best Model R2 Score: 0.020168274445878542\n",
      "Random Forest Regressor Predictions vs Actual:\n",
      "       Predicted  Actual\n",
      "12118   1.189702       1\n",
      "12618   1.401595       2\n",
      "2997    1.191356       1\n",
      "11637   1.316452       1\n",
      "10367   1.013419       1\n",
      "...          ...     ...\n",
      "4969    1.150414       1\n",
      "15453   1.148415       1\n",
      "1653    1.486272       1\n",
      "5219    1.203589       1\n",
      "14817   1.379262       2\n",
      "\n",
      "[2449 rows x 2 columns]\n",
      "\n",
      "Random Forest Regressor Model Mean Squared Error:\n",
      "0.612401587930257\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "\n",
      "KNN Regressor Best Model Parameters: {'regressor__n_neighbors': 7, 'regressor__weights': 'distance'}\n",
      "KNN Regressor Best Model R2 Score: -0.06065272848068881\n",
      "KNN Regressor Predictions vs Actual:\n",
      "       Predicted  Actual\n",
      "12118   1.000000       1\n",
      "12618   1.137794       2\n",
      "2997    1.116365       1\n",
      "11637   1.183250       1\n",
      "10367   1.000000       1\n",
      "...          ...     ...\n",
      "4969    1.171852       1\n",
      "15453   1.000000       1\n",
      "1653    1.133041       1\n",
      "5219    1.150910       1\n",
      "14817   1.125839       2\n",
      "\n",
      "[2449 rows x 2 columns]\n",
      "\n",
      "KNN Regressor Model Mean Squared Error:\n",
      "0.6629152723104551\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "\n",
      "Linear Regression Best Model Parameters: {}\n",
      "Linear Regression Best Model R2 Score: 0.029935782133457156\n",
      "Linear Regression Predictions vs Actual:\n",
      "       Predicted  Actual\n",
      "12118   1.190619       1\n",
      "12618   1.359512       2\n",
      "2997    1.239019       1\n",
      "11637   1.289383       1\n",
      "10367   1.217704       1\n",
      "...          ...     ...\n",
      "4969    1.227053       1\n",
      "15453   1.159524       1\n",
      "1653    1.420727       1\n",
      "5219    1.215109       1\n",
      "14817   1.242551       2\n",
      "\n",
      "[2449 rows x 2 columns]\n",
      "\n",
      "Linear Regression Model Mean Squared Error:\n",
      "0.6062968282434738\n"
     ]
    }
   ],
   "source": [
    "# Iterate through regression models and perform GridSearchCV\n",
    "for name, (pipeline, params) in regression_models_and_parameters.items():\n",
    "    grid_search = GridSearchCV(pipeline, params, cv=5, n_jobs=-1, verbose=1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    # Get R2 score and predictions\n",
    "    r2_score = best_model.score(X_test, y_test)\n",
    "    predictions = best_model.predict(X_test)\n",
    "    \n",
    "    print(f\"\\n{name} Best Model Parameters: {grid_search.best_params_}\")\n",
    "    print(f\"{name} Best Model R2 Score: {r2_score}\")\n",
    "    print(f\"{name} Predictions vs Actual:\")\n",
    "    print(pd.DataFrame({\"Predicted\": predictions, \"Actual\": y_test}))\n",
    "\n",
    "    # Confusion Matrix and Classification Report (not applicable for regression but we can show other metrics)\n",
    "    print(f\"\\n{name} Model Mean Squared Error:\")\n",
    "\n",
    "    print(mean_squared_error(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if hasattr(best_model.named_steps['regressor'], 'feature_importances_'):\n",
    "    importance = best_model.named_steps['regressor'].feature_importances_\n",
    "    features = new_input_df.columns\n",
    "    importance_df = pd.DataFrame({'Feature': features, 'Importance': importance})\n",
    "    importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "    print(f\"{name} Feature Importances:\")\n",
    "    print(importance_df)\n",
    "\n",
    "    print(importance_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
